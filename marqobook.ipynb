{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the marqo client. Make sure to activate the marqo server running in docker with the correct port (8882)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'errors': False,\n",
       " 'processingTimeMs': 6632.005779996689,\n",
       " 'index_name': 'book-index',\n",
       " 'items': [{'status': 200, '_id': '46ca8746-65ce-4ed8-994b-6a2676893916'},\n",
       "  {'status': 200, '_id': '5f0a63b5-8ef1-433d-973f-75faa648b973'},\n",
       "  {'status': 200, '_id': 'dad5ee64-cb01-4118-8f38-5c143ceb0d7a'},\n",
       "  {'status': 200, '_id': 'db74951b-e0f9-45e9-8d8a-d8ac1d77574b'},\n",
       "  {'status': 200, '_id': 'f95597cb-fb5b-403b-8242-440b6b492827'},\n",
       "  {'status': 200, '_id': 'bb682333-bfcf-47ad-b503-1b89344e720b'}]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import marqo\n",
    "import json\n",
    "\n",
    "mq = marqo.Client(url='http://localhost:8882')\n",
    "index_name = \"book-index\"\n",
    "\n",
    "# Check if this index has been created, if so, delete\n",
    "try:\n",
    "    mq.index(index_name).delete()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "mq.create_index(index_name, model=\"hf/e5-base-v2\")\n",
    "\n",
    "# Load pre-cleaned data\n",
    "with open(r'docs\\QGenda Whitepaper_cleaned.json', 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Index to marqo\n",
    "mq.index(index_name).add_documents(\n",
    "    data,\n",
    "    tensor_fields=[\"text\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe the results of a basic tensor search. This should return the most related text to the question, based on a semantic search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hits': [{'index': 3, '_id': 'db74951b-e0f9-45e9-8d8a-d8ac1d77574b', 'text': \"\\nAs a result, over half of our respondents reported experiencing major difficulties with their current exam room scheduling solutions. Management of exam rooms is considered time-intensive, and the technology is difficult to use and error-prone. The result is outdated or incorrect information and the inability to positively impact utilization. Transparency is also a key roadblock. Executives routinely cite the lack of analytics required to even understand their current exam room utilization. These issues are compounded when each department uses a separate scheduling system, further limiting transparency and a clinic's ability to fully utilize exam rooms across departments. As a result, only 31% of health system executives report being happy with their current solution. This lack of proper scheduling causes unnecessary delays and limits patient throughput. If significant wait times pervade a health system at an enterprise level, patients may go elsewhere for care. To maximize the investment in new processes and exam room scheduling technology, health systems must set utilization targets, measure, and make changes needed to achieve goals. As most healthcare executives agree, clinics should be targeting a utilization level above 80%. Forward-thinking executives are considering investments in process and technology that optimize exam room utilization now. In fact, 70% of those surveyed expressed an interest in solutions that can solve their exam room underutilization challenges\", '_highlights': [{'text': 'As most healthcare executives agree, clinics should be targeting a utilization level above 80%. Forward-thinking executives are considering investments in process and technology that optimize exam room utilization now.'}], '_score': 0.874682308041172}, {'index': 1, '_id': '5f0a63b5-8ef1-433d-973f-75faa648b973', 'text': 'As healthcare leaders reimagine patient access and care delivery in a post-pandemic world, there is an emerging story around the need to optimize clinic exam room utilization. Better utilization can improve operating efficiency, patient satisfaction, and revenue capture. The 2020 Porter Research study of 100 health system executive leaders identified the many challenges faced today with exam room scheduling, future expectations for optimizing exam rooms, and the impact that proper exam room scheduling can have on a health systemâ€™s P&L. Increasing Scrutiny on Clinic Exam Rooms. With the limited funds available for health system capital expenditures, executives must optimize their existing physical space while simultaneously remaining adaptable to fluctuations in patient demand. In the short term, health systems may experience an influx of patients who delayed elective surgeries, treatments for minor health issues, and preventative visits due to COVID-19. As a result, clinics could be overwhelmed. Patients may experience significant wait times and cumbersome appointment rescheduling. Inefficient scheduling could result in additional revenue leakage, because patients who cannot secure timely appointments at their first-choice location may decide to go elsewhere. In the longer term, executives will need to focus on closing a 20-point utilization gap. Health system executives surveyed identified optimal exam room utilization to be between 80 and 89%. However,', '_highlights': [{'text': 'Inefficient scheduling could result in additional revenue leakage, because patients who cannot secure timely appointments at their first-choice location may decide to go elsewhere. In the longer term, executives will need to focus on closing a 20-point utilization gap.'}], '_score': 0.8711736184763094}], 'query': 'What utilization gap do executives need to focus on?', 'limit': 2, 'offset': 0, 'processingTimeMs': 178}\n"
     ]
    }
   ],
   "source": [
    "question=\"What utilization gap do executives need to focus on?\"\n",
    "\n",
    "# Return just two results\n",
    "results = mq.index(\"book-index\").search(\n",
    "    q=question,\n",
    "    limit=2\n",
    ")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up prompt for GPT\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Given the following extracted parts of a long document (\"SOURCES\") and a question (\"QUESTION\"), create a final answer one paragraph long.\n",
    "Don't try to make up an answer and use the text in the SOURCES only for the answer. If you don't know the answer, just say that you don't know.\n",
    "QUESTION: {question}\n",
    "=========\n",
    "SOURCES:\n",
    "{summaries}\n",
    "=========\n",
    "ANSWER:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"summaries\", \"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI key accessed.\n",
      "According to the sources, healthcare executives should focus on closing a 20-point utilization gap in the long term, with a target utilization level of above 80%. This gap is important to address as it can lead to patient dissatisfaction, loss of revenue, and patients seeking care elsewhere. In the short term, executives should also prioritize optimizing exam room utilization to handle an influx of patients due to COVID-19. By investing in new processes and technology, and setting measurable goals, clinics can better manage patient throughput and ensure a high level of utilization.\n"
     ]
    }
   ],
   "source": [
    "# Run LLM\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.chains import LLMChain\n",
    "from utilities import extract_text_from_highlights, get_openai_key\n",
    "\n",
    "api_key = get_openai_key()\n",
    "\n",
    "highlights, texts = extract_text_from_highlights(results, token_limit=150)\n",
    "docs = [Document(page_content=f\"Source [{ind}]:\" + t) for ind, t in enumerate(texts)]\n",
    "llm = OpenAI(temperature=0.9)\n",
    "# Create the chain using the RunnableSequence\n",
    "chain_qa = prompt | llm\n",
    "llm_results = chain_qa.invoke({\"summaries\": docs, \"question\": results['query']}, return_only_outputs=True)\n",
    "print(llm_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
